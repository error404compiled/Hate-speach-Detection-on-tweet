{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import pr\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\91966\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"labeled_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24778</th>\n",
       "      <td>25291</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>you's a muthaf***in lie &amp;#8220;@LifeAsKing: @2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24779</th>\n",
       "      <td>25292</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>you've gone and broke the wrong heart baby, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24780</th>\n",
       "      <td>25294</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>young buck wanna eat!!.. dat nigguh like I ain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24781</th>\n",
       "      <td>25295</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>youu got wild bitches tellin you lies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24782</th>\n",
       "      <td>25296</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>~~Ruffled | Ntac Eileen Dahlia - Beautiful col...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24783 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
       "0               0      3            0                   0        3      2   \n",
       "1               1      3            0                   3        0      1   \n",
       "2               2      3            0                   3        0      1   \n",
       "3               3      3            0                   2        1      1   \n",
       "4               4      6            0                   6        0      1   \n",
       "...           ...    ...          ...                 ...      ...    ...   \n",
       "24778       25291      3            0                   2        1      1   \n",
       "24779       25292      3            0                   1        2      2   \n",
       "24780       25294      3            0                   3        0      1   \n",
       "24781       25295      6            0                   6        0      1   \n",
       "24782       25296      3            0                   0        3      2   \n",
       "\n",
       "                                                   tweet  \n",
       "0      !!! RT @mayasolovely: As a woman you shouldn't...  \n",
       "1      !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
       "2      !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
       "3      !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
       "4      !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  \n",
       "...                                                  ...  \n",
       "24778  you's a muthaf***in lie &#8220;@LifeAsKing: @2...  \n",
       "24779  you've gone and broke the wrong heart baby, an...  \n",
       "24780  young buck wanna eat!!.. dat nigguh like I ain...  \n",
       "24781              youu got wild bitches tellin you lies  \n",
       "24782  ~~Ruffled | Ntac Eileen Dahlia - Beautiful col...  \n",
       "\n",
       "[24783 rows x 7 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "      <td>No Hate and Offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "      <td>Offensive Language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "      <td>Offensive Language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "      <td>Offensive Language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "      <td>Offensive Language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24778</th>\n",
       "      <td>you's a muthaf***in lie &amp;#8220;@LifeAsKing: @2...</td>\n",
       "      <td>Offensive Language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24779</th>\n",
       "      <td>you've gone and broke the wrong heart baby, an...</td>\n",
       "      <td>No Hate and Offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24780</th>\n",
       "      <td>young buck wanna eat!!.. dat nigguh like I ain...</td>\n",
       "      <td>Offensive Language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24781</th>\n",
       "      <td>youu got wild bitches tellin you lies</td>\n",
       "      <td>Offensive Language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24782</th>\n",
       "      <td>~~Ruffled | Ntac Eileen Dahlia - Beautiful col...</td>\n",
       "      <td>No Hate and Offensive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24783 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweet  \\\n",
       "0      !!! RT @mayasolovely: As a woman you shouldn't...   \n",
       "1      !!!!! RT @mleew17: boy dats cold...tyga dwn ba...   \n",
       "2      !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...   \n",
       "3      !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...   \n",
       "4      !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...   \n",
       "...                                                  ...   \n",
       "24778  you's a muthaf***in lie &#8220;@LifeAsKing: @2...   \n",
       "24779  you've gone and broke the wrong heart baby, an...   \n",
       "24780  young buck wanna eat!!.. dat nigguh like I ain...   \n",
       "24781              youu got wild bitches tellin you lies   \n",
       "24782  ~~Ruffled | Ntac Eileen Dahlia - Beautiful col...   \n",
       "\n",
       "                      labels  \n",
       "0      No Hate and Offensive  \n",
       "1         Offensive Language  \n",
       "2         Offensive Language  \n",
       "3         Offensive Language  \n",
       "4         Offensive Language  \n",
       "...                      ...  \n",
       "24778     Offensive Language  \n",
       "24779  No Hate and Offensive  \n",
       "24780     Offensive Language  \n",
       "24781     Offensive Language  \n",
       "24782  No Hate and Offensive  \n",
       "\n",
       "[24783 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"labels\"] = data[\"class\"].map({0: \"Hate Speech Detected\", 1: \"Offensive Language\", 2: \"No Hate and Offensive\"})\n",
    "data = data[[\"tweet\", \"labels\"]]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "stemmer = nltk.SnowballStemmer(\"english\")\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "stopword=set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    text = [word for word in text.split(' ') if word not in stopword]\n",
    "    text=\" \".join(text)\n",
    "    text = [stemmer.stem(word) for word in text.split(' ')]\n",
    "    text=\" \".join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-b9528bfd1d02>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"tweet\"] = data[\"tweet\"].apply(clean)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rt mayasolov woman shouldnt complain clean ho...</td>\n",
       "      <td>No Hate and Offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rt  boy dat coldtyga dwn bad cuffin dat hoe  ...</td>\n",
       "      <td>Offensive Language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rt urkindofbrand dawg rt  ever fuck bitch sta...</td>\n",
       "      <td>Offensive Language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rt cganderson vivabas look like tranni</td>\n",
       "      <td>Offensive Language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt shenikarobert shit hear might true might f...</td>\n",
       "      <td>Offensive Language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24778</th>\n",
       "      <td>yous muthafin lie   coreyemanuel right tl tras...</td>\n",
       "      <td>Offensive Language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24779</th>\n",
       "      <td>youv gone broke wrong heart babi drove redneck...</td>\n",
       "      <td>No Hate and Offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24780</th>\n",
       "      <td>young buck wanna eat dat nigguh like aint fuck...</td>\n",
       "      <td>Offensive Language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24781</th>\n",
       "      <td>youu got wild bitch tellin lie</td>\n",
       "      <td>Offensive Language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24782</th>\n",
       "      <td>ruffl  ntac eileen dahlia  beauti color combin...</td>\n",
       "      <td>No Hate and Offensive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24783 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweet  \\\n",
       "0       rt mayasolov woman shouldnt complain clean ho...   \n",
       "1       rt  boy dat coldtyga dwn bad cuffin dat hoe  ...   \n",
       "2       rt urkindofbrand dawg rt  ever fuck bitch sta...   \n",
       "3                 rt cganderson vivabas look like tranni   \n",
       "4       rt shenikarobert shit hear might true might f...   \n",
       "...                                                  ...   \n",
       "24778  yous muthafin lie   coreyemanuel right tl tras...   \n",
       "24779  youv gone broke wrong heart babi drove redneck...   \n",
       "24780  young buck wanna eat dat nigguh like aint fuck...   \n",
       "24781                     youu got wild bitch tellin lie   \n",
       "24782  ruffl  ntac eileen dahlia  beauti color combin...   \n",
       "\n",
       "                      labels  \n",
       "0      No Hate and Offensive  \n",
       "1         Offensive Language  \n",
       "2         Offensive Language  \n",
       "3         Offensive Language  \n",
       "4         Offensive Language  \n",
       "...                      ...  \n",
       "24778     Offensive Language  \n",
       "24779  No Hate and Offensive  \n",
       "24780     Offensive Language  \n",
       "24781     Offensive Language  \n",
       "24782  No Hate and Offensive  \n",
       "\n",
       "[24783 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"tweet\"] = data[\"tweet\"].apply(clean)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8762684924807433"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array(data[\"tweet\"])\n",
    "y = np.array(data[\"labels\"])\n",
    "\n",
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(x) # Fit the Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train,y_train)\n",
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'streamlit'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-06f05c83aa6a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mhate_speech_detection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-10-06f05c83aa6a>\u001b[0m in \u001b[0;36mhate_speech_detection\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mhate_speech_detection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mimport\u001b[0m \u001b[0mstreamlit\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mst\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"[Hate Speech Detection System]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0muser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext_area\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Enter any Tweet: \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'streamlit'"
     ]
    }
   ],
   "source": [
    "def hate_speech_detection():\n",
    "    import streamlit as st\n",
    "    st.title(\"[Hate Speech Detection System]\")\n",
    "    user = st.text_area(\"Enter any Tweet: \")\n",
    "    if len(user) < 1:\n",
    "        st.write(\"  \")\n",
    "    else:\n",
    "        sample = user\n",
    "        data = cv.transform([sample]).toarray()\n",
    "        a = clf.predict(data)\n",
    "        st.title(a)\n",
    "hate_speech_detection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlitNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -p (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -2p (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -1p (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -0p (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -2p (c:\\programdata\\anaconda3\\lib\\site-packages)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Using cached streamlit-1.5.0-py2.py3-none-any.whl (9.7 MB)\n",
      "Collecting cachetools>=4.0\n",
      "  Using cached cachetools-5.0.0-py3-none-any.whl (9.1 kB)\n",
      "Requirement already satisfied: toml in c:\\programdata\\anaconda3\\lib\\site-packages (from streamlit) (0.10.1)\n",
      "Collecting pyarrow\n",
      "  Using cached pyarrow-6.0.1.tar.gz (770 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Collecting altair>=3.2.0\n",
      "  Using cached altair-4.2.0-py3-none-any.whl (812 kB)\n",
      "Requirement already satisfied: attrs in c:\\programdata\\anaconda3\\lib\\site-packages (from streamlit) (19.3.0)\n",
      "Requirement already satisfied: tornado>=5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from streamlit) (6.0.4)\n",
      "Requirement already satisfied: python-dateutil in c:\\programdata\\anaconda3\\lib\\site-packages (from streamlit) (2.8.1)\n",
      "Requirement already satisfied: click>=7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from streamlit) (7.1.2)\n",
      "Collecting astor\n",
      "  Using cached astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from streamlit) (20.4)\n",
      "Collecting protobuf!=3.11,>=3.6.0\n",
      "  Using cached protobuf-3.19.3-cp38-cp38-win32.whl (775 kB)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from streamlit) (1.18.5)\n",
      "Requirement already satisfied: pandas>=0.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from streamlit) (1.0.5)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from streamlit) (2.24.0)\n",
      "Collecting base58\n",
      "  Using cached base58-2.1.1-py3-none-any.whl (5.6 kB)\n",
      "Requirement already satisfied: watchdog in c:\\programdata\\anaconda3\\lib\\site-packages (from streamlit) (0.10.3)\n",
      "Collecting pympler>=0.9\n",
      "  Using cached Pympler-1.0.1-py3-none-any.whl (164 kB)\n",
      "Collecting tzlocal\n",
      "  Using cached tzlocal-4.1-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from streamlit) (7.2.0)\n",
      "Collecting validators\n",
      "  Using cached validators-0.18.2-py3-none-any.whl (19 kB)\n",
      "Collecting blinker\n",
      "  Using cached blinker-1.4.tar.gz (111 kB)\n",
      "Collecting gitpython!=3.1.19\n",
      "  Using cached GitPython-3.1.26-py3-none-any.whl (180 kB)\n",
      "Collecting pydeck>=0.1.dev5\n",
      "  Using cached pydeck-0.7.1-py2.py3-none-any.whl (4.3 MB)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from altair>=3.2.0->streamlit) (3.2.0)\n",
      "Requirement already satisfied: toolz in c:\\programdata\\anaconda3\\lib\\site-packages (from altair>=3.2.0->streamlit) (0.10.0)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from altair>=3.2.0->streamlit) (2.11.2)\n",
      "Requirement already satisfied: entrypoints in c:\\programdata\\anaconda3\\lib\\site-packages (from altair>=3.2.0->streamlit) (0.3)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Using cached gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Using cached smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit) (0.16.0)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit) (49.2.0.post20200714)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit) (1.15.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=0.21.0->streamlit) (2020.1)\n",
      "Requirement already satisfied: ipykernel>=5.1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydeck>=0.1.dev5->streamlit) (5.3.2)\n",
      "Requirement already satisfied: traitlets>=4.3.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydeck>=0.1.dev5->streamlit) (4.3.3)\n",
      "Requirement already satisfied: ipywidgets>=7.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydeck>=0.1.dev5->streamlit) (7.5.1)\n",
      "Requirement already satisfied: ipython>=5.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (7.16.1)\n",
      "Requirement already satisfied: jupyter-client in c:\\programdata\\anaconda3\\lib\\site-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (6.1.6)\n",
      "Requirement already satisfied: decorator in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (4.4.2)\n",
      "Requirement already satisfied: backcall in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.2.0)\n",
      "Requirement already satisfied: jedi>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.17.1)\n",
      "Requirement already satisfied: pickleshare in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (3.0.5)\n",
      "Requirement already satisfied: pygments in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (2.6.1)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.4.3)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.0.7)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (3.5.1)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jedi>=0.10->ipython>=5.0.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.7.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->altair>=3.2.0->streamlit) (1.1.1)\n",
      "Requirement already satisfied: jupyter-core in c:\\programdata\\anaconda3\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (4.6.3)\n",
      "Requirement already satisfied: ipython-genutils in c:\\programdata\\anaconda3\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.2.0)\n",
      "Requirement already satisfied: wcwidth in c:\\programdata\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.0.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.2.5)\n",
      "Requirement already satisfied: notebook>=4.4.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (6.0.3)\n",
      "Requirement already satisfied: terminado>=0.8.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.8.3)\n",
      "Requirement already satisfied: prometheus-client in c:\\programdata\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.8.0)\n",
      "Requirement already satisfied: Send2Trash in c:\\programdata\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.5.0)\n",
      "Requirement already satisfied: nbconvert in c:\\programdata\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.6.1)\n",
      "Requirement already satisfied: pyzmq>=17 in c:\\programdata\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (19.0.1)\n",
      "Requirement already satisfied: pywin32>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jupyter-core->nbformat>=4.2.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (227)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.4.2)\n",
      "Requirement already satisfied: defusedxml in c:\\programdata\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.6.0)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.8.4)\n",
      "Requirement already satisfied: bleach in c:\\programdata\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (3.1.5)\n",
      "Requirement already satisfied: testpath in c:\\programdata\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.4.4)\n",
      "Requirement already satisfied: webencodings in c:\\programdata\\anaconda3\\lib\\site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.5.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging->streamlit) (2.4.7)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->streamlit) (1.25.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->streamlit) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->streamlit) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->streamlit) (3.0.4)\n",
      "Collecting tzdata\n",
      "  Using cached tzdata-2021.5-py2.py3-none-any.whl (339 kB)\n",
      "Collecting backports.zoneinfo\n",
      "  Downloading backports.zoneinfo-0.2.1-cp38-cp38-win32.whl (36 kB)\n",
      "Collecting pytz-deprecation-shim\n",
      "  Using cached pytz_deprecation_shim-0.1.0.post0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: pathtools>=0.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from watchdog->streamlit) (0.1.2)\n",
      "Building wheels for collected packages: blinker, pyarrow\n",
      "  Building wheel for blinker (setup.py): started\n",
      "  Building wheel for blinker (setup.py): finished with status 'done'\n",
      "  Created wheel for blinker: filename=blinker-1.4-py3-none-any.whl size=13455 sha256=375f6836dc44d79f57d6e4629ca3f475582276e339aa256fa00491555673040c\n",
      "  Stored in directory: c:\\users\\91966\\appdata\\local\\pip\\cache\\wheels\\b7\\a5\\68\\fe632054a5eadd531c7a49d740c50eb6adfbeca822b4eab8d4\n",
      "  Building wheel for pyarrow (PEP 517): started\n",
      "  Building wheel for pyarrow (PEP 517): finished with status 'error'\n",
      "Successfully built blinker\n",
      "Failed to build pyarrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: Ignoring invalid distribution -1p (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -0p (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'C:\\ProgramData\\Anaconda3\\python.exe' 'C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py' build_wheel 'C:\\Users\\91966\\AppData\\Local\\Temp\\tmp9zxe9kp5'\n",
      "       cwd: C:\\Users\\91966\\AppData\\Local\\Temp\\pip-install-tiaqq341\\pyarrow_a95291bf297647f69c647b369ac36d9c\n",
      "  Complete output (231 lines):\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win32-3.8\n",
      "  creating build\\lib.win32-3.8\\pyarrow\n",
      "  copying pyarrow\\benchmark.py -> build\\lib.win32-3.8\\pyarrow\n",
      "  copying pyarrow\\cffi.py -> build\\lib.win32-3.8\\pyarrow\n",
      "  copying pyarrow\\compat.py -> build\\lib.win32-3.8\\pyarrow\n",
      "  copying pyarrow\\compute.py -> build\\lib.win32-3.8\\pyarrow\n",
      "  copying pyarrow\\csv.py -> build\\lib.win32-3.8\\pyarrow\n",
      "  copying pyarrow\\cuda.py -> build\\lib.win32-3.8\\pyarrow\n",
      "  copying pyarrow\\dataset.py -> build\\lib.win32-3.8\\pyarrow\n",
      "  copying pyarrow\\feather.py -> build\\lib.win32-3.8\\pyarrow\n",
      "  copying pyarrow\\filesystem.py -> build\\lib.win32-3.8\\pyarrow\n",
      "  copying pyarrow\\flight.py -> build\\lib.win32-3.8\\pyarrow\n",
      "  copying pyarrow\\fs.py -> build\\lib.win32-3.8\\pyarrow\n",
      "  copying pyarrow\\hdfs.py -> build\\lib.win32-3.8\\pyarrow\n",
      "  copying pyarrow\\ipc.py -> build\\lib.win32-3.8\\pyarrow\n",
      "  copying pyarrow\\json.py -> build\\lib.win32-3.8\\pyarrow\n",
      "  copying pyarrow\\jvm.py -> build\\lib.win32-3.8\\pyarrow\n",
      "  copying pyarrow\\orc.py -> build\\lib.win32-3.8\\pyarrow\n",
      "  copying pyarrow\\pandas_compat.py -> build\\lib.win32-3.8\\pyarrow\n",
      "  copying pyarrow\\parquet.py -> build\\lib.win32-3.8\\pyarrow\n",
      "  copying pyarrow\\plasma.py -> build\\lib.win32-3.8\\pyarrow\n",
      "  copying pyarrow\\serialization.py -> build\\lib.win32-3.8\\pyarrow\n",
      "  copying pyarrow\\types.py -> build\\lib.win32-3.8\\pyarrow\n",
      "  copying pyarrow\\util.py -> build\\lib.win32-3.8\\pyarrow\n",
      "  copying pyarrow\\_generated_version.py -> build\\lib.win32-3.8\\pyarrow\n",
      "  copying pyarrow\\__init__.py -> build\\lib.win32-3.8\\pyarrow\n",
      "  creating build\\lib.win32-3.8\\pyarrow\\tests\n",
      "  copying pyarrow\\tests\\arrow_7980.py -> build\\lib.win32-3.8\\pyarrow\\tests\n",
      "  copying pyarrow\\tests\\conftest.py -> build\\lib.win32-3.8\\pyarrow\\tests\n",
      "  copying pyarrow\\tests\\deserialize_buffer.py -> build\\lib.win32-3.8\\pyarrow\\tests\n",
      "  copying pyarrow\\tests\\pandas_examples.py -> build\\lib.win32-3.8\\pyarrow\\tests\n",
      "  copying pyarrow\\tests\\pandas_threaded_import.py -> build\\lib.win32-3.8\\pyarrow\\tests\n",
      "  copying pyarrow\\tests\\strategies.py -> build\\lib.win32-3.8\\pyarrow\\tests\n",
      "  copying pyarrow\\tests\\test_adhoc_memory_leak.py -> build\\lib.win32-3.8\\pyarrow\\tests\n",
      "  copying pyarrow\\tests\\test_array.py -> build\\lib.win32-3.8\\pyarrow\\tests\n",
      "  copying pyarrow\\tests\\test_builder.py -> build\\lib.win32-3.8\\pyarrow\\tests\n",
      "  copying pyarrow\\tests\\test_cffi.py -> build\\lib.win32-3.8\\pyarrow\\tests\n",
      "  copying pyarrow\\tests\\test_compute.py -> build\\lib.win32-3.8\\pyarrow\\tests\n",
      "  copying pyarrow\\tests\\test_convert_builtin.py -> build\\lib.win32-3.8\\pyarrow\\tests\n",
      "  copying pyarrow\\tests\\test_csv.py -> build\\lib.win32-3.8\\pyarrow\\tests\n",
      "  copying pyarrow\\tests\\test_cuda.py -> build\\lib.win32-3.8\\pyarrow\\tests\n",
      "  copying pyarrow\\tests\\test_cuda_numba_interop.py -> build\\lib.win32-3.8\\pyarrow\\tests\n",
      "  copying pyarrow\\tests\\test_cython.py -> build\\lib.win32-3.8\\pyarrow\\tests\n",
      "  copying pyarrow\\tests\\test_dataset.py -> build\\lib.win32-3.8\\pyarrow\\tests\n",
      "  copying pyarrow\\tests\\test_deprecations.py -> build\\lib.win32-3.8\\pyarrow\\tests\n",
      "  copying pyarrow\\tests\\test_extension_type.py -> build\\lib.win32-3.8\\pyarrow\\tests\n",
      "  copying pyarrow\\tests\\test_feather.py -> build\\lib.win32-3.8\\pyarrow\\tests\n",
      "  copying pyarrow\\tests\\test_filesystem.py -> build\\lib.win32-3.8\\pyarrow\\tests\n",
      "  copying pyarrow\\tests\\test_flight.py -> build\\lib.win32-3.8\\pyarrow\\tests\n",
      "  copying pyarrow\\tests\\test_fs.py -> build\\lib.win32-3.8\\pyarrow\\tests\n",
      "  copying pyarrow\\tests\\test_gandiva.py -> build\\lib.win32-3.8\\pyarrow\\tests\n",
      "  copying pyarrow\\tests\\test_hdfs.py -> build\\lib.win32-3.8\\pyarrow\\tests\n",
      "  copying pyarrow\\tests\\test_io.py -> build\\lib.win32-3.8\\pyarrow\\tests\n",
      "  copying pyarrow\\tests\\test_ipc.py -> build\\lib.win32-3.8\\pyarrow\\tests\n",
      "  copying pyarrow\\tests\\test_json.py -> build\\lib.win32-3.8\\pyarrow\\tests\n",
      "  copying pyarrow\\tests\\test_jvm.py -> build\\lib.win32-3.8\\pyarrow\\tests\n",
      "  copying pyarrow\\tests\\test_memory.py -> build\\lib.win32-3.8\\pyarrow\\tests\n",
      "  copying pyarrow\\tests\\test_misc.py -> build\\lib.win32-3.8\\pyarrow\\tests\n",
      "  copying pyarrow\\tests\\test_orc.py -> build\\lib.win32-3.8\\pyarrow\\tests\n",
      "  copying pyarrow\\tests\\test_pandas.py -> build\\lib.win32-3.8\\pyarrow\\tests\n",
      "  copying pyarrow\\tests\\test_plasma.py -> build\\lib.win32-3.8\\pyarrow\\tests\n",
      "  copying pyarrow\\tests\\test_plasma_tf_op.py -> build\\lib.win32-3.8\\pyarrow\\tests\n",
      "  copying pyarrow\\tests\\test_scalars.py -> build\\lib.win32-3.8\\pyarrow\\tests\n",
      "  copying pyarrow\\tests\\test_schema.py -> build\\lib.win32-3.8\\pyarrow\\tests\n",
      "  copying pyarrow\\tests\\test_serialization.py -> build\\lib.win32-3.8\\pyarrow\\tests\n",
      "  copying pyarrow\\tests\\test_serialization_deprecated.py -> build\\lib.win32-3.8\\pyarrow\\tests\n",
      "  copying pyarrow\\tests\\test_sparse_tensor.py -> build\\lib.win32-3.8\\pyarrow\\tests\n",
      "  copying pyarrow\\tests\\test_strategies.py -> build\\lib.win32-3.8\\pyarrow\\tests\n",
      "  copying pyarrow\\tests\\test_table.py -> build\\lib.win32-3.8\\pyarrow\\tests\n",
      "  copying pyarrow\\tests\\test_tensor.py -> build\\lib.win32-3.8\\pyarrow\\tests\n",
      "  copying pyarrow\\tests\\test_types.py -> build\\lib.win32-3.8\\pyarrow\\tests\n",
      "  copying pyarrow\\tests\\test_util.py -> build\\lib.win32-3.8\\pyarrow\\tests\n",
      "  copying pyarrow\\tests\\util.py -> build\\lib.win32-3.8\\pyarrow\\tests\n",
      "  copying pyarrow\\tests\\__init__.py -> build\\lib.win32-3.8\\pyarrow\\tests\n",
      "  running egg_info\n",
      "  writing pyarrow.egg-info\\PKG-INFO\n",
      "  writing dependency_links to pyarrow.egg-info\\dependency_links.txt\n",
      "  writing entry points to pyarrow.egg-info\\entry_points.txt\n",
      "  writing requirements to pyarrow.egg-info\\requires.txt\n",
      "  writing top-level names to pyarrow.egg-info\\top_level.txt\n",
      "  listing git files failed - pretending there aren't any\n",
      "  reading manifest file 'pyarrow.egg-info\\SOURCES.txt'\n",
      "  reading manifest template 'MANIFEST.in'\n",
      "  warning: no files found matching '..\\LICENSE.txt'\n",
      "  warning: no files found matching '..\\NOTICE.txt'\n",
      "  warning: no previously-included files matching '*.so' found anywhere in distribution\n",
      "  warning: no previously-included files matching '*.pyc' found anywhere in distribution\n",
      "  warning: no previously-included files matching '*~' found anywhere in distribution\n",
      "  warning: no previously-included files matching '#*' found anywhere in distribution\n",
      "  warning: no previously-included files matching '.git*' found anywhere in distribution\n",
      "  warning: no previously-included files matching '.DS_Store' found anywhere in distribution\n",
      "  no previously-included directories found matching '.asv'\n",
      "  writing manifest file 'pyarrow.egg-info\\SOURCES.txt'\n",
      "  copying pyarrow\\__init__.pxd -> build\\lib.win32-3.8\\pyarrow\n",
      "  copying pyarrow\\_compute.pxd -> build\\lib.win32-3.8\\pyarrow\n",
      "  copying pyarrow\\_compute.pyx -> build\\lib.win32-3.8\\pyarrow\n",
      "  copying pyarrow\\_csv.pxd -> build\\lib.win32-3.8\\pyarrow\n",
      "  copying pyarrow\\_csv.pyx -> build\\lib.win32-3.8\\pyarrow\n",
      "  copying pyarrow\\_cuda.pxd -> build\\lib.win32-3.8\\pyarrow\n",
      "  copying pyarrow\\_cuda.pyx -> build\\lib.win32-3.8\\pyarrow\n",
      "  copying pyarrow\\_dataset.pxd -> build\\lib.win32-3.8\\pyarrow\n",
      "  copying pyarrow\\_dataset.pyx -> build\\lib.win32-3.8\\pyarrow\n",
      "  copying pyarrow\\_dataset_orc.pyx -> build\\lib.win32-3.8\\pyarrow\n",
      "  copying pyarrow\\_feather.pyx -> build\\lib.win32-3.8\\pyarrow\n",
      "  copying pyarrow\\_flight.pyx -> build\\lib.win32-3.8\\pyarrow\n",
      "  copying pyarrow\\_fs.pxd -> build\\lib.win32-3.8\\pyarrow\n",
      "  copying pyarrow\\_fs.pyx -> build\\lib.win32-3.8\\pyarrow\n",
      "  copying pyarrow\\_hdfs.pyx -> build\\lib.win32-3.8\\pyarrow\n",
      "  copying pyarrow\\_hdfsio.pyx -> build\\lib.win32-3.8\\pyarrow\n",
      "  copying pyarrow\\_json.pyx -> build\\lib.win32-3.8\\pyarrow\n",
      "  copying pyarrow\\_orc.pxd -> build\\lib.win32-3.8\\pyarrow\n",
      "  copying pyarrow\\_orc.pyx -> build\\lib.win32-3.8\\pyarrow\n",
      "  copying pyarrow\\_parquet.pxd -> build\\lib.win32-3.8\\pyarrow\n",
      "  copying pyarrow\\_parquet.pyx -> build\\lib.win32-3.8\\pyarrow\n",
      "  copying pyarrow\\_plasma.pyx -> build\\lib.win32-3.8\\pyarrow\n",
      "  copying pyarrow\\_s3fs.pyx -> build\\lib.win32-3.8\\pyarrow\n",
      "  copying pyarrow\\array.pxi -> build\\lib.win32-3.8\\pyarrow\n",
      "  copying pyarrow\\benchmark.pxi -> build\\lib.win32-3.8\\pyarrow\n",
      "  copying pyarrow\\builder.pxi -> build\\lib.win32-3.8\\pyarrow\n",
      "  copying pyarrow\\compat.pxi -> build\\lib.win32-3.8\\pyarrow\n",
      "  copying pyarrow\\config.pxi -> build\\lib.win32-3.8\\pyarrow\n",
      "  copying pyarrow\\error.pxi -> build\\lib.win32-3.8\\pyarrow\n",
      "  copying pyarrow\\gandiva.pyx -> build\\lib.win32-3.8\\pyarrow\n",
      "  copying pyarrow\\io.pxi -> build\\lib.win32-3.8\\pyarrow\n",
      "  copying pyarrow\\ipc.pxi -> build\\lib.win32-3.8\\pyarrow\n",
      "  copying pyarrow\\lib.pxd -> build\\lib.win32-3.8\\pyarrow\n",
      "  copying pyarrow\\lib.pyx -> build\\lib.win32-3.8\\pyarrow\n",
      "  copying pyarrow\\memory.pxi -> build\\lib.win32-3.8\\pyarrow\n",
      "  copying pyarrow\\pandas-shim.pxi -> build\\lib.win32-3.8\\pyarrow\n",
      "  copying pyarrow\\public-api.pxi -> build\\lib.win32-3.8\\pyarrow\n",
      "  copying pyarrow\\scalar.pxi -> build\\lib.win32-3.8\\pyarrow\n",
      "  copying pyarrow\\serialization.pxi -> build\\lib.win32-3.8\\pyarrow\n",
      "  copying pyarrow\\table.pxi -> build\\lib.win32-3.8\\pyarrow\n",
      "  copying pyarrow\\tensor.pxi -> build\\lib.win32-3.8\\pyarrow\n",
      "  copying pyarrow\\types.pxi -> build\\lib.win32-3.8\\pyarrow\n",
      "  creating build\\lib.win32-3.8\\pyarrow\\includes\n",
      "  copying pyarrow\\includes\\__init__.pxd -> build\\lib.win32-3.8\\pyarrow\\includes\n",
      "  copying pyarrow\\includes\\common.pxd -> build\\lib.win32-3.8\\pyarrow\\includes\n",
      "  copying pyarrow\\includes\\libarrow.pxd -> build\\lib.win32-3.8\\pyarrow\\includes\n",
      "  copying pyarrow\\includes\\libarrow_cuda.pxd -> build\\lib.win32-3.8\\pyarrow\\includes\n",
      "  copying pyarrow\\includes\\libarrow_dataset.pxd -> build\\lib.win32-3.8\\pyarrow\\includes\n",
      "  copying pyarrow\\includes\\libarrow_feather.pxd -> build\\lib.win32-3.8\\pyarrow\\includes\n",
      "  copying pyarrow\\includes\\libarrow_flight.pxd -> build\\lib.win32-3.8\\pyarrow\\includes\n",
      "  copying pyarrow\\includes\\libarrow_fs.pxd -> build\\lib.win32-3.8\\pyarrow\\includes\n",
      "  copying pyarrow\\includes\\libgandiva.pxd -> build\\lib.win32-3.8\\pyarrow\\includes\n",
      "  copying pyarrow\\includes\\libplasma.pxd -> build\\lib.win32-3.8\\pyarrow\\includes\n",
      "  creating build\\lib.win32-3.8\\pyarrow\\tensorflow\n",
      "  copying pyarrow\\tensorflow\\plasma_op.cc -> build\\lib.win32-3.8\\pyarrow\\tensorflow\n",
      "  creating build\\lib.win32-3.8\\pyarrow\\vendored\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  copying pyarrow\\vendored\\__init__.py -> build\\lib.win32-3.8\\pyarrow\\vendored\n",
      "  copying pyarrow\\vendored\\version.py -> build\\lib.win32-3.8\\pyarrow\\vendored\n",
      "  copying pyarrow\\tests\\bound_function_visit_strings.pyx -> build\\lib.win32-3.8\\pyarrow\\tests\n",
      "  copying pyarrow\\tests\\pyarrow_cython_example.pyx -> build\\lib.win32-3.8\\pyarrow\\tests\n",
      "  creating build\\lib.win32-3.8\\pyarrow\\tests\\data\n",
      "  creating build\\lib.win32-3.8\\pyarrow\\tests\\data\\feather\n",
      "  copying pyarrow\\tests\\data\\feather\\v0.17.0.version=2-compression=lz4.feather -> build\\lib.win32-3.8\\pyarrow\\tests\\data\\feather\n",
      "  creating build\\lib.win32-3.8\\pyarrow\\tests\\data\\orc\n",
      "  copying pyarrow\\tests\\data\\orc\\README.md -> build\\lib.win32-3.8\\pyarrow\\tests\\data\\orc\n",
      "  copying pyarrow\\tests\\data\\orc\\TestOrcFile.emptyFile.jsn.gz -> build\\lib.win32-3.8\\pyarrow\\tests\\data\\orc\n",
      "  copying pyarrow\\tests\\data\\orc\\TestOrcFile.emptyFile.orc -> build\\lib.win32-3.8\\pyarrow\\tests\\data\\orc\n",
      "  copying pyarrow\\tests\\data\\orc\\TestOrcFile.test1.jsn.gz -> build\\lib.win32-3.8\\pyarrow\\tests\\data\\orc\n",
      "  copying pyarrow\\tests\\data\\orc\\TestOrcFile.test1.orc -> build\\lib.win32-3.8\\pyarrow\\tests\\data\\orc\n",
      "  copying pyarrow\\tests\\data\\orc\\TestOrcFile.testDate1900.jsn.gz -> build\\lib.win32-3.8\\pyarrow\\tests\\data\\orc\n",
      "  copying pyarrow\\tests\\data\\orc\\TestOrcFile.testDate1900.orc -> build\\lib.win32-3.8\\pyarrow\\tests\\data\\orc\n",
      "  copying pyarrow\\tests\\data\\orc\\decimal.jsn.gz -> build\\lib.win32-3.8\\pyarrow\\tests\\data\\orc\n",
      "  copying pyarrow\\tests\\data\\orc\\decimal.orc -> build\\lib.win32-3.8\\pyarrow\\tests\\data\\orc\n",
      "  creating build\\lib.win32-3.8\\pyarrow\\tests\\data\\parquet\n",
      "  copying pyarrow\\tests\\data\\parquet\\v0.7.1.all-named-index.parquet -> build\\lib.win32-3.8\\pyarrow\\tests\\data\\parquet\n",
      "  copying pyarrow\\tests\\data\\parquet\\v0.7.1.column-metadata-handling.parquet -> build\\lib.win32-3.8\\pyarrow\\tests\\data\\parquet\n",
      "  copying pyarrow\\tests\\data\\parquet\\v0.7.1.parquet -> build\\lib.win32-3.8\\pyarrow\\tests\\data\\parquet\n",
      "  copying pyarrow\\tests\\data\\parquet\\v0.7.1.some-named-index.parquet -> build\\lib.win32-3.8\\pyarrow\\tests\\data\\parquet\n",
      "  creating build\\lib.win32-3.8\\pyarrow\\tests\\parquet\n",
      "  copying pyarrow\\tests\\parquet\\common.py -> build\\lib.win32-3.8\\pyarrow\\tests\\parquet\n",
      "  copying pyarrow\\tests\\parquet\\conftest.py -> build\\lib.win32-3.8\\pyarrow\\tests\\parquet\n",
      "  copying pyarrow\\tests\\parquet\\test_basic.py -> build\\lib.win32-3.8\\pyarrow\\tests\\parquet\n",
      "  copying pyarrow\\tests\\parquet\\test_compliant_nested_type.py -> build\\lib.win32-3.8\\pyarrow\\tests\\parquet\n",
      "  copying pyarrow\\tests\\parquet\\test_data_types.py -> build\\lib.win32-3.8\\pyarrow\\tests\\parquet\n",
      "  copying pyarrow\\tests\\parquet\\test_dataset.py -> build\\lib.win32-3.8\\pyarrow\\tests\\parquet\n",
      "  copying pyarrow\\tests\\parquet\\test_datetime.py -> build\\lib.win32-3.8\\pyarrow\\tests\\parquet\n",
      "  copying pyarrow\\tests\\parquet\\test_metadata.py -> build\\lib.win32-3.8\\pyarrow\\tests\\parquet\n",
      "  copying pyarrow\\tests\\parquet\\test_pandas.py -> build\\lib.win32-3.8\\pyarrow\\tests\\parquet\n",
      "  copying pyarrow\\tests\\parquet\\test_parquet_file.py -> build\\lib.win32-3.8\\pyarrow\\tests\\parquet\n",
      "  copying pyarrow\\tests\\parquet\\test_parquet_writer.py -> build\\lib.win32-3.8\\pyarrow\\tests\\parquet\n",
      "  running build_ext\n",
      "  creating C:\\Users\\91966\\AppData\\Local\\Temp\\pip-install-tiaqq341\\pyarrow_a95291bf297647f69c647b369ac36d9c\\build\\temp.win32-3.8\n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py\", line 280, in <module>\n",
      "      main()\n",
      "    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py\", line 263, in main\n",
      "      json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py\", line 204, in build_wheel\n",
      "      return _build_backend().build_wheel(wheel_directory, config_settings,\n",
      "    File \"C:\\Users\\91966\\AppData\\Local\\Temp\\pip-build-env-que8t5t3\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 221, in build_wheel\n",
      "      return self._build_with_temp_dir(['bdist_wheel'], '.whl',\n",
      "    File \"C:\\Users\\91966\\AppData\\Local\\Temp\\pip-build-env-que8t5t3\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 207, in _build_with_temp_dir\n",
      "      self.run_setup()\n",
      "    File \"C:\\Users\\91966\\AppData\\Local\\Temp\\pip-build-env-que8t5t3\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 258, in run_setup\n",
      "      super(_BuildMetaLegacyBackend,\n",
      "    File \"C:\\Users\\91966\\AppData\\Local\\Temp\\pip-build-env-que8t5t3\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 150, in run_setup\n",
      "      exec(compile(code, __file__, 'exec'), locals())\n",
      "    File \"setup.py\", line 589, in <module>\n",
      "      setup(\n",
      "    File \"C:\\Users\\91966\\AppData\\Local\\Temp\\pip-build-env-que8t5t3\\overlay\\Lib\\site-packages\\setuptools\\__init__.py\", line 159, in setup\n",
      "      return distutils.core.setup(**attrs)\n",
      "    File \"C:\\ProgramData\\Anaconda3\\lib\\distutils\\core.py\", line 148, in setup\n",
      "      dist.run_commands()\n",
      "    File \"C:\\ProgramData\\Anaconda3\\lib\\distutils\\dist.py\", line 966, in run_commands\n",
      "      self.run_command(cmd)\n",
      "    File \"C:\\ProgramData\\Anaconda3\\lib\\distutils\\dist.py\", line 985, in run_command\n",
      "      cmd_obj.run()\n",
      "    File \"C:\\Users\\91966\\AppData\\Local\\Temp\\pip-build-env-que8t5t3\\overlay\\Lib\\site-packages\\wheel\\bdist_wheel.py\", line 299, in run\n",
      "      self.run_command('build')\n",
      "    File \"C:\\ProgramData\\Anaconda3\\lib\\distutils\\cmd.py\", line 313, in run_command\n",
      "      self.distribution.run_command(command)\n",
      "    File \"C:\\ProgramData\\Anaconda3\\lib\\distutils\\dist.py\", line 985, in run_command\n",
      "      cmd_obj.run()\n",
      "    File \"C:\\ProgramData\\Anaconda3\\lib\\distutils\\command\\build.py\", line 135, in run\n",
      "      self.run_command(cmd_name)\n",
      "    File \"C:\\ProgramData\\Anaconda3\\lib\\distutils\\cmd.py\", line 313, in run_command\n",
      "      self.distribution.run_command(command)\n",
      "    File \"C:\\ProgramData\\Anaconda3\\lib\\distutils\\dist.py\", line 985, in run_command\n",
      "      cmd_obj.run()\n",
      "    File \"setup.py\", line 96, in run\n",
      "      self._run_cmake()\n",
      "    File \"setup.py\", line 288, in _run_cmake\n",
      "      raise RuntimeError('Not supported on 32-bit Windows')\n",
      "  RuntimeError: Not supported on 32-bit Windows\n",
      "  ----------------------------------------\n",
      "  ERROR: Failed building wheel for pyarrow\n",
      "ERROR: Could not build wheels for pyarrow which use PEP 517 and cannot be installed directly\n",
      "WARNING: Ignoring invalid distribution -p (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -2p (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -1p (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -0p (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -2p (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -1p (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -0p (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -2p (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -1p (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -0p (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: You are using pip version 21.1.1; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\ProgramData\\Anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install streamlit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
